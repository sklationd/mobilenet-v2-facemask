{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS470_PJ.ipynb의 사본의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sklationd/mobilenet-v2-facemask/blob/main/CS470_PJ_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFifDWoz20QY"
      },
      "source": [
        "# 0. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWemigXMuUqk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y_g93YMKedb"
      },
      "source": [
        "# 1. Check is GPU available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASflVQJpKdwm"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LWKvs-oK7SM"
      },
      "source": [
        "# 2. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo8G_KsJK6cu",
        "outputId": "6be5627a-2501-469c-a5e3-6b92e1590124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "root = '/gdrive/My Drive/CS470/Project/dataset'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EFhO3f0NdGs"
      },
      "source": [
        "# 3. Define datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl9BYYPtNjLB"
      },
      "source": [
        "class MaskDataset(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "        # load all image files, sorting them to\n",
        "        # ensure that they are aligned\n",
        "        # self.imgs = list(sorted(os.listdir(Path(root) / 'images')))\n",
        "        #self.imgs=list(sorted(os.listdir(Path(root))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        folder=idx // 1000\n",
        "        num= idx % 1000\n",
        "        folder_name = 'data'+str(folder)\n",
        "        file_list=list(sorted(os.listdir(Path(root)/folder_name)))\n",
        "        file_name=file_list[num]\n",
        "        img_path = os.path.join(Path(root)/folder_name,file_name)\n",
        "        img=Image.open(img_path).convert(\"RGB\")\n",
        "        #print(folder_name)\n",
        "\n",
        "        #file_name = self.img[idx]\n",
        "        #img_path= os.path.join(Path(root)/'dataset/',file_name)\n",
        "        #img= Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        #~~~~~~.jpg                       0 ; without mask\n",
        "        #00001_Mask.jpg                   1\n",
        "        #00001_Mask_Chin.jpg.             2\n",
        "        #00001_Mask_Mouth_Chin.jpg        3\n",
        "        #00001_Mask_Nose_Mouth.jpg        4\n",
        "\n",
        "        p_list=str(file_name).split('_')\n",
        "        if len(p_list)==1:\n",
        "          label=0\n",
        "        elif len(p_list)==2:\n",
        "          label=1\n",
        "        elif len(p_list)==3:\n",
        "          label=2\n",
        "        elif p_list[-1]=='Chin.jpg':\n",
        "          label=3\n",
        "        else:\n",
        "          label=4\n",
        "          \n",
        "        #Generate Label\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return 20000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dNa-kYyLy4F"
      },
      "source": [
        "# 4. Build dataloader and transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dts-OlpGOP_S"
      },
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bK1F9MFRcsS"
      },
      "source": [
        "dataset = MaskDataset(preprocess)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGs60j8MUNNt",
        "outputId": "7d959e31-bd5e-465d-fc9c-1a14712f3925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import cv2\n",
        "\n",
        "print('size of train datasets :',len(train_loader.dataset))\n",
        "print('size of test datasets  :',len(test_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of train datasets : 16000\n",
            "size of test datasets  : 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR2vpmVLXN2i"
      },
      "source": [
        "# 5. Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ias2d-IevhPI"
      },
      "source": [
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from typing import Callable, Any, Optional, List\n",
        "\n",
        "\n",
        "__all__ = ['MobileNetV2', 'mobilenet_v2']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'mobilenet_v2': 'https://download.pytorch.org/models/mobilenet_v2-b0353104.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Sequential):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_planes: int,\n",
        "        out_planes: int,\n",
        "        kernel_size: int = 3,\n",
        "        stride: int = 1,\n",
        "        groups: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        super(ConvBNReLU, self).__init__(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
        "            norm_layer(out_planes),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        inp: int,\n",
        "        oup: int,\n",
        "        stride: int,\n",
        "        expand_ratio: int,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        hidden_dim = int(round(inp * expand_ratio))\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        layers: List[nn.Module] = []\n",
        "        if expand_ratio != 1:\n",
        "            # pw\n",
        "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1, norm_layer=norm_layer))\n",
        "        layers.extend([\n",
        "            # dw\n",
        "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim, norm_layer=norm_layer),\n",
        "            # pw-linear\n",
        "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "            norm_layer(oup),\n",
        "        ])\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 1000,\n",
        "        width_mult: float = 1.0,\n",
        "        inverted_residual_setting: Optional[List[List[int]]] = None,\n",
        "        round_nearest: int = 8,\n",
        "        block: Optional[Callable[..., nn.Module]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        MobileNet V2 main class\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): Number of classes\n",
        "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
        "            inverted_residual_setting: Network structure\n",
        "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
        "            Set to 1 to turn off rounding\n",
        "            block: Module specifying inverted residual building block for mobilenet\n",
        "            norm_layer: Module specifying the normalization layer to use\n",
        "\n",
        "        \"\"\"\n",
        "        super(MobileNetV2, self).__init__()\n",
        "\n",
        "        if block is None:\n",
        "            block = InvertedResidual\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "\n",
        "        if inverted_residual_setting is None:\n",
        "            inverted_residual_setting = [\n",
        "                # t, c, n, s\n",
        "                [1, 16, 1, 1],\n",
        "                [6, 24, 2, 2],\n",
        "                [6, 32, 3, 2],\n",
        "                [6, 64, 4, 2],\n",
        "                [6, 96, 3, 1],\n",
        "                [6, 160, 3, 2],\n",
        "                [6, 320, 1, 1],\n",
        "            ]\n",
        "\n",
        "        # only check the first element, assuming user knows t,c,n,s are required\n",
        "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
        "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
        "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
        "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
        "        features: List[nn.Module] = [ConvBNReLU(3, input_channel, stride=2, norm_layer=norm_layer)]\n",
        "        # building inverted residual blocks\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                features.append(block(input_channel, output_channel, stride, expand_ratio=t, norm_layer=norm_layer))\n",
        "                input_channel = output_channel\n",
        "        # building last several layers\n",
        "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1, norm_layer=norm_layer))\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*features)\n",
        "\n",
        "        # building classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(self.last_channel, num_classes),\n",
        "        )\n",
        "\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # This exists since TorchScript doesn't support inheritance, so the superclass method\n",
        "        # (this one) needs to have a name other than `forward` that can be accessed in a subclass\n",
        "        x = self.features(x)\n",
        "        # Cannot use \"squeeze\" as batch-size can be 1 => must use reshape with x.shape[0]\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1)).reshape(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tC7p2aUXNae",
        "outputId": "1b00fbf2-39b9-4e24-fbc0-c128a182ad9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# model = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=True)\n",
        "model = MobileNetV2(num_classes=5)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): ConvBNReLU(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvBNReLU(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwj4TMsyhIor"
      },
      "source": [
        "# 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDjaLKOd3mAt"
      },
      "source": [
        "# pre-setup\n",
        "num_epochs = 10\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "learning_rate = 0.0005\n",
        "optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=0.000001)\n",
        "loss_func = torch.nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxO2GOrUg3RP"
      },
      "source": [
        "# for plotting\n",
        "from matplotlib import pyplot as plt\n",
        "train_loss_list = []\n",
        "test_loss_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhDSfvXv3s13"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  test_loss = 0\n",
        "  best_test_loss = 1\n",
        "\n",
        "  for i, samples in enumerate(train_loader):\n",
        "      imgs, annotations = samples\n",
        "      imgs, annotations = imgs.to(device), annotations.to(device)\n",
        "      \n",
        "      output = model(imgs)\n",
        "      loss = loss_func(output,annotations)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      print(f'Iteration: {i+1}/{len(train_loader)}, Loss: {loss.item()}')\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  avg_train_loss = epoch_loss/len(train_loader)\n",
        "\n",
        "  # Save result for plotting\n",
        "  train_loss_list.append(avg_train_loss)\n",
        "\n",
        "  # Print epoch's test loss\n",
        "  print(f'Epoch {epoch} train loss: {avg_train_loss}')\n",
        "\n",
        "  # validation\n",
        "  for i,test_samples in enumerate(test_loader):\n",
        "    test_imgs, test_annotations = test_samples\n",
        "    test_imgs, test_annotations = test_imgs.to(device), test_annotations.to(device)\n",
        "\n",
        "    test_output = model(test_imgs)\n",
        "    loss = loss_func(test_output, test_annotations)\n",
        "    test_loss += loss.item()\n",
        "\n",
        "    # print(f'Iteration: {i+1}/{len(test_loader)}, Loss: {loss.item()}')\n",
        "  \n",
        "  avg_test_loss = test_loss/len(test_loader)\n",
        "\n",
        "  # Save result for plotting\n",
        "  test_loss_list.append(avg_test_loss)\n",
        "\n",
        "  # Print epoch's test loss\n",
        "  print(f'Epoch {epoch} test loss: {avg_test_loss}')\n",
        "  \n",
        "  # save best\n",
        "  if best_test_loss > avg_test_loss:\n",
        "    best_test_loss = avg_test_loss\n",
        "    torch.save(model.state_dict(), Path(root) / 'best.pt')\n",
        "\n",
        "  print('-------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iigMuWghd27",
        "outputId": "5f736f4d-1f6f-4d82-cc37-d832f10874a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "# Plot\n",
        "print(train_loss_list)\n",
        "print(test_loss_list)\n",
        "\n",
        "plt.plot(train_loss_list)\n",
        "plt.plot(test_loss_list)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train/Test Loss')\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9758126680850983, 0.41526123297214507, 0.2490502351820469, 0.16624340713024138, 0.11480260559916497, 0.08713625229150057, 0.06878995877876878, 0.05646837978810072, 0.04871623854711652, 0.04254413226805627]\n",
            "[0.5794232080853174, 0.28768386372498106, 0.19386532299575351, 0.12741789641597914, 0.09774567003524492, 0.07900400764294087, 0.06323327127075384, 0.057903507354831886, 0.054785524494946, 0.04476545584787216]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}