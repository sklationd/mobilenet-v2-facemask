{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS470_PJ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sklationd/mobilenet-v2-facemask/blob/main/CS470_PJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFifDWoz20QY"
      },
      "source": [
        "# 0. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWemigXMuUqk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y_g93YMKedb"
      },
      "source": [
        "# 1. Check is GPU available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASflVQJpKdwm"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LWKvs-oK7SM"
      },
      "source": [
        "# 2. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo8G_KsJK6cu",
        "outputId": "ee83e241-7b72-48ef-9d4c-3d8aec9514a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "root = '/gdrive/My Drive/CS470/Project'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EFhO3f0NdGs"
      },
      "source": [
        "# 3. Define datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl9BYYPtNjLB"
      },
      "source": [
        "class MaskDataset(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "        # load all image files, sorting them to\n",
        "        # ensure that they are aligned\n",
        "        # self.imgs = list(sorted(os.listdir(Path(root) / 'images')))\n",
        "        self.imgs=list(sorted(os.listdir(Path(root)/'dataset')))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_name = self.imgs[idx]\n",
        "        img_path = os.path.join(Path(root)/ 'dataset/',file_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")    \n",
        "        \n",
        "        #~~~~~~.jpg                       0 ; without mask\n",
        "        #00001_Mask.jpg                   1\n",
        "        #00001_Mask_Chin.jpg.             2\n",
        "        #00001_Mask_Mouth_Chin.jpg        3\n",
        "        #00001_Mask_Nose_Mouth.jpg        4\n",
        "\n",
        "        p_list=str(file_name).split('_')\n",
        "        if len(p_list)==1:\n",
        "          label=0\n",
        "        elif len(p_list)==2:\n",
        "          label=1\n",
        "        elif len(p_list)==3:\n",
        "          label=2\n",
        "        elif p_list[-1]=='Chin.jpg':\n",
        "          label=3\n",
        "        else:\n",
        "          label=4\n",
        "          \n",
        "        #Generate Label\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dNa-kYyLy4F"
      },
      "source": [
        "# 4. Build dataloader and transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dts-OlpGOP_S"
      },
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bK1F9MFRcsS"
      },
      "source": [
        "dataset = MaskDataset(preprocess)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=4, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=4, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGs60j8MUNNt",
        "outputId": "a882de0b-1866-410a-e364-ba534c942223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import cv2\n",
        "\n",
        "print('size of train datasets :',len(train_loader.dataset))\n",
        "print('size of test datasets  :',len(test_loader.dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of train datasets : 2145\n",
            "size of test datasets  : 537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR2vpmVLXN2i"
      },
      "source": [
        "# 5. Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ias2d-IevhPI"
      },
      "source": [
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from typing import Callable, Any, Optional, List\n",
        "\n",
        "\n",
        "__all__ = ['MobileNetV2', 'mobilenet_v2']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'mobilenet_v2': 'https://download.pytorch.org/models/mobilenet_v2-b0353104.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Sequential):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_planes: int,\n",
        "        out_planes: int,\n",
        "        kernel_size: int = 3,\n",
        "        stride: int = 1,\n",
        "        groups: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        super(ConvBNReLU, self).__init__(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
        "            norm_layer(out_planes),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        inp: int,\n",
        "        oup: int,\n",
        "        stride: int,\n",
        "        expand_ratio: int,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        hidden_dim = int(round(inp * expand_ratio))\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        layers: List[nn.Module] = []\n",
        "        if expand_ratio != 1:\n",
        "            # pw\n",
        "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1, norm_layer=norm_layer))\n",
        "        layers.extend([\n",
        "            # dw\n",
        "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim, norm_layer=norm_layer),\n",
        "            # pw-linear\n",
        "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "            norm_layer(oup),\n",
        "        ])\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 1000,\n",
        "        width_mult: float = 1.0,\n",
        "        inverted_residual_setting: Optional[List[List[int]]] = None,\n",
        "        round_nearest: int = 8,\n",
        "        block: Optional[Callable[..., nn.Module]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        MobileNet V2 main class\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): Number of classes\n",
        "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
        "            inverted_residual_setting: Network structure\n",
        "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
        "            Set to 1 to turn off rounding\n",
        "            block: Module specifying inverted residual building block for mobilenet\n",
        "            norm_layer: Module specifying the normalization layer to use\n",
        "\n",
        "        \"\"\"\n",
        "        super(MobileNetV2, self).__init__()\n",
        "\n",
        "        if block is None:\n",
        "            block = InvertedResidual\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "\n",
        "        if inverted_residual_setting is None:\n",
        "            inverted_residual_setting = [\n",
        "                # t, c, n, s\n",
        "                [1, 16, 1, 1],\n",
        "                [6, 24, 2, 2],\n",
        "                [6, 32, 3, 2],\n",
        "                [6, 64, 4, 2],\n",
        "                [6, 96, 3, 1],\n",
        "                [6, 160, 3, 2],\n",
        "                [6, 320, 1, 1],\n",
        "            ]\n",
        "\n",
        "        # only check the first element, assuming user knows t,c,n,s are required\n",
        "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
        "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
        "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
        "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
        "        features: List[nn.Module] = [ConvBNReLU(3, input_channel, stride=2, norm_layer=norm_layer)]\n",
        "        # building inverted residual blocks\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                features.append(block(input_channel, output_channel, stride, expand_ratio=t, norm_layer=norm_layer))\n",
        "                input_channel = output_channel\n",
        "        # building last several layers\n",
        "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1, norm_layer=norm_layer))\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*features)\n",
        "\n",
        "        # building classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(self.last_channel, num_classes),\n",
        "        )\n",
        "\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # This exists since TorchScript doesn't support inheritance, so the superclass method\n",
        "        # (this one) needs to have a name other than `forward` that can be accessed in a subclass\n",
        "        x = self.features(x)\n",
        "        # Cannot use \"squeeze\" as batch-size can be 1 => must use reshape with x.shape[0]\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1)).reshape(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tC7p2aUXNae",
        "outputId": "5aa5b3ec-55f8-4133-ab57-a0ae8c0878a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# model = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=True)\n",
        "model = MobileNetV2(num_classes=5)\n",
        "model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): ConvBNReLU(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNReLU(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNReLU(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvBNReLU(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwj4TMsyhIor"
      },
      "source": [
        "# 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDjaLKOd3mAt"
      },
      "source": [
        "# pre-setup\n",
        "num_epochs = 25\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "learning_rate = 0.0005\n",
        "optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=0.000001)\n",
        "loss_func = torch.nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxO2GOrUg3RP"
      },
      "source": [
        "# for plotting\n",
        "from matplotlib import pyplot as plt\n",
        "train_loss_list = []\n",
        "test_loss_list = []"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhDSfvXv3s13",
        "outputId": "885b9cef-0e97-466f-e55e-54c82e9ca124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  test_loss = 0\n",
        "  best_test_loss = 1\n",
        "\n",
        "  for i, samples in enumerate(train_loader):\n",
        "      imgs, annotations = samples\n",
        "      imgs, annotations = imgs.to(device), annotations.to(device)\n",
        "      \n",
        "      output = model(imgs)\n",
        "      loss = loss_func(output,annotations)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # print(f'Iteration: {i+1}/{len(train_loader)}, Loss: {loss.item()}')\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  avg_train_loss = epoch_loss/len(train_loader)\n",
        "\n",
        "  # Save result for plotting\n",
        "  train_loss_list.append(avg_train_loss)\n",
        "\n",
        "  # Print epoch's test loss\n",
        "  print(f'Epoch {epoch} train loss: {avg_train_loss}')\n",
        "\n",
        "  # validation\n",
        "  for i,test_samples in enumerate(test_loader):\n",
        "    test_imgs, test_annotations = test_samples\n",
        "    test_imgs, test_annotations = test_imgs.to(device), test_annotations.to(device)\n",
        "\n",
        "    test_output = model(test_imgs)\n",
        "    loss = loss_func(test_output, test_annotations)\n",
        "    test_loss += loss.item()\n",
        "\n",
        "    # print(f'Iteration: {i+1}/{len(test_loader)}, Loss: {loss.item()}')\n",
        "  \n",
        "  avg_test_loss = test_loss/len(test_loader)\n",
        "\n",
        "  # Save result for plotting\n",
        "  test_loss_list.append(avg_test_loss)\n",
        "\n",
        "  # Print epoch's test loss\n",
        "  print(f'Epoch {epoch} test loss: {avg_test_loss}')\n",
        "  \n",
        "  # save best\n",
        "  if best_test_loss > avg_test_loss:\n",
        "    best_test_loss = avg_test_loss\n",
        "    torch.save(model.state_dict(), Path(root) / 'best.pt')\n",
        "\n",
        "  print('-------------------------------------')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Epoch 0 train loss: 0.905455257251054\n",
            "Epoch 0 test loss: 0.5921200524325724\n",
            "-------------------------------------\n",
            "Epoch: 1\n",
            "Epoch 1 train loss: 0.469991042193726\n",
            "Epoch 1 test loss: 0.46089572318726113\n",
            "-------------------------------------\n",
            "Epoch: 2\n",
            "Epoch 2 train loss: 0.4081660717954682\n",
            "Epoch 2 test loss: 0.4073224286376326\n",
            "-------------------------------------\n",
            "Epoch: 3\n",
            "Epoch 3 train loss: 0.31251938977700205\n",
            "Epoch 3 test loss: 0.26296961393759205\n",
            "-------------------------------------\n",
            "Epoch: 4\n",
            "Epoch 4 train loss: 0.2569641067613492\n",
            "Epoch 4 test loss: 0.22284231393563528\n",
            "-------------------------------------\n",
            "Epoch: 5\n",
            "Epoch 5 train loss: 0.20214405272579172\n",
            "Epoch 5 test loss: 0.22660015676584508\n",
            "-------------------------------------\n",
            "Epoch: 6\n",
            "Epoch 6 train loss: 0.20396460632202207\n",
            "Epoch 6 test loss: 0.19719226013834554\n",
            "-------------------------------------\n",
            "Epoch: 7\n",
            "Epoch 7 train loss: 0.17423707505322134\n",
            "Epoch 7 test loss: 0.24395161847825403\n",
            "-------------------------------------\n",
            "Epoch: 8\n",
            "Epoch 8 train loss: 0.1716930005316548\n",
            "Epoch 8 test loss: 0.14118051614129432\n",
            "-------------------------------------\n",
            "Epoch: 9\n",
            "Epoch 9 train loss: 0.1745822192035317\n",
            "Epoch 9 test loss: 0.13600566841282502\n",
            "-------------------------------------\n",
            "Epoch: 10\n",
            "Epoch 10 train loss: 0.15342724093390384\n",
            "Epoch 10 test loss: 0.12077234034012589\n",
            "-------------------------------------\n",
            "Epoch: 11\n",
            "Epoch 11 train loss: 0.12140383492583787\n",
            "Epoch 11 test loss: 0.1665925592046093\n",
            "-------------------------------------\n",
            "Epoch: 12\n",
            "Epoch 12 train loss: 0.12345391400249456\n",
            "Epoch 12 test loss: 0.13396923802965494\n",
            "-------------------------------------\n",
            "Epoch: 13\n",
            "Epoch 13 train loss: 0.12064469575398953\n",
            "Epoch 13 test loss: 0.1261585758369485\n",
            "-------------------------------------\n",
            "Epoch: 14\n",
            "Epoch 14 train loss: 0.10735816568712005\n",
            "Epoch 14 test loss: 0.11450487297218016\n",
            "-------------------------------------\n",
            "Epoch: 15\n",
            "Epoch 15 train loss: 0.10351689954247548\n",
            "Epoch 15 test loss: 0.12271517011837137\n",
            "-------------------------------------\n",
            "Epoch: 16\n",
            "Epoch 16 train loss: 0.1059018244558869\n",
            "Epoch 16 test loss: 0.09831882095464539\n",
            "-------------------------------------\n",
            "Epoch: 17\n",
            "Epoch 17 train loss: 0.11002217780040348\n",
            "Epoch 17 test loss: 0.09899290079699347\n",
            "-------------------------------------\n",
            "Epoch: 18\n",
            "Epoch 18 train loss: 0.08538994798848659\n",
            "Epoch 18 test loss: 0.10544040165237945\n",
            "-------------------------------------\n",
            "Epoch: 19\n",
            "Epoch 19 train loss: 0.08479520005620131\n",
            "Epoch 19 test loss: 0.07561639417695848\n",
            "-------------------------------------\n",
            "Epoch: 20\n",
            "Epoch 20 train loss: 0.09214987013306039\n",
            "Epoch 20 test loss: 0.12686025375948737\n",
            "-------------------------------------\n",
            "Epoch: 21\n",
            "Epoch 21 train loss: 0.07720501473463129\n",
            "Epoch 21 test loss: 0.0840611305863907\n",
            "-------------------------------------\n",
            "Epoch: 22\n",
            "Epoch 22 train loss: 0.061043449193005084\n",
            "Epoch 22 test loss: 0.05816076717003145\n",
            "-------------------------------------\n",
            "Epoch: 23\n",
            "Epoch 23 train loss: 0.07677464771172937\n",
            "Epoch 23 test loss: 0.10486408971137953\n",
            "-------------------------------------\n",
            "Epoch: 24\n",
            "Epoch 24 train loss: 0.06439216277458891\n",
            "Epoch 24 test loss: 0.07473586165406569\n",
            "-------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iigMuWghd27",
        "outputId": "bd24849c-60a1-4302-f578-23cc06bfd977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "# Plot\n",
        "print(train_loss_list)\n",
        "print(test_loss_list)\n",
        "\n",
        "plt.plot(train_loss_list)\n",
        "plt.plot(test_loss_list)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train/Test Loss')\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.905455257251054, 0.469991042193726, 0.4081660717954682, 0.31251938977700205, 0.2569641067613492, 0.20214405272579172, 0.20396460632202207, 0.17423707505322134, 0.1716930005316548, 0.1745822192035317, 0.15342724093390384, 0.12140383492583787, 0.12345391400249456, 0.12064469575398953, 0.10735816568712005, 0.10351689954247548, 0.1059018244558869, 0.11002217780040348, 0.08538994798848659, 0.08479520005620131, 0.09214987013306039, 0.07720501473463129, 0.061043449193005084, 0.07677464771172937, 0.06439216277458891]\n",
            "[0.5921200524325724, 0.46089572318726113, 0.4073224286376326, 0.26296961393759205, 0.22284231393563528, 0.22660015676584508, 0.19719226013834554, 0.24395161847825403, 0.14118051614129432, 0.13600566841282502, 0.12077234034012589, 0.1665925592046093, 0.13396923802965494, 0.1261585758369485, 0.11450487297218016, 0.12271517011837137, 0.09831882095464539, 0.09899290079699347, 0.10544040165237945, 0.07561639417695848, 0.12686025375948737, 0.0840611305863907, 0.05816076717003145, 0.10486408971137953, 0.07473586165406569]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUdd7+8fcnk94DhCIJTQFBxKBBFBvYdW3rropl7aLuo2577OvquuvPttVn3bWy6AqWteJaVwVBkSpFei9BSkhIIKRPvr8/ziQECJAAk0ly7td15ZozZ87MfA6jc8/5lnPMOYeIiAhAVKQLEBGRlkOhICIidRQKIiJSR6EgIiJ1FAoiIlJHoSAiInUUCiIiUkehIL5hZh+Z2TWRrkOkJVMoSItmZiX1/mrMrKze/Sub8lrOuXOccy814b1jzWyzmS2v955BMyuvd/++/din0Wb2+31s48zssKa+tsiBio50ASJ745xLrl02s1XAjc65z3bdzsyinXPVB/ntTwZmO+dOr/c+E4BXnHMvHOT3EmkRdKQgrZKZDTOzPDO728w2AP80swwz+4+Z5ZvZltByVr3nTDCzG0PL15rZV2b2h9C2K83snF3e5lzgw33Ucb2ZLQy9xidm1j203szsz2a2ycy2mtl3ZjbAzEYCVwJ3hY403m/ifqeZ2cuhfVxtZr82s6jQY4eZ2ZdmVhw6wnl9b7U05X3FPxQK0pp1BtoB3YGReP89/zN0vxtQBvxtL88fAiwGOgBPAC+amdV7/Fzggz092cwuBO4DLgYygUnAq6GHz8Q70ugDpAGXAgXOueeAMcATzrlk59z5TdhfgP8LvV4v4BTgauC60GO/Az4FMoCs0LZ7rKWJ7ys+oVCQ1qwGeNA5V+GcK3POFTjn3nLOlTrntgGP4H1x7slq59zzzrkg8BLQBegEYGaHAtHOucV7ef4twKPOuYWhpqv/B+SEjhaqgBTgcMBC26w/kJ01swAwArjXObfNObcK+CPwk9AmVXiBeIhzrtw591W99Qe1Fmm7FArSmuU758pr75hZopk9G2pW2QpMBNJDX6YN2VC74JwrDS3W9mGcC3y0j/fvDvzVzIrMrAgoBAzo6pz7Au8o5Wlgk5k9Z2apTd3BXXQAYoDV9datBrqGlu8Kvf80M5tvZtcDhKkWaaMUCtKa7Xre918BfYEhzrlUvCYT8L4om2qf/QnAWuBm51x6vb8E59xkAOfcU865Y4D+eE03d+6h7sbazI6jgVrdgHWh99vgnLvJOXcIcDPw99oRTHupRWQnCgVpS1Lw+hGKzKwd8OD+vIiZJQLHAuP3sekzwL1mdkToeWlmdkloebCZDTGzGGA7UI7X3AWwEa9PYF9izSy+9i+07g3gETNLCTVT/RJ4JfSel9TrWN+CFz41+6hFZCcKBWlL/gIk4P2ingJ8vJ+vcyrwTf2mqYY4594BHgdeCzVXzQNqRzClAs/jfTmvxuvYfTL02ItA/1Cz07t7eYv5eCFX+3cdcDveF/sK4CtgLDAqtP1gYKqZlQDjgJ8551bsoxaRnZiuvCayMzP7OzDPOff3SNci0tw0eU1kd7OBJs0fEGkrdKQgIiJ11KcgIiJ1Wl3zUYcOHVyPHj0iXYaISKsyc+bMzc65zH1t1+pCoUePHsyYMSPSZYiItCpmtnrfW6n5SERE6lEoiIhIHYWCiIjUaXV9CiIiTVVVVUVeXh7l5XudpN4mxMfHk5WVRUxMzH49X6EgIm1eXl4eKSkp9OjRg50vmdG2OOcoKCggLy+Pnj177tdrqPlIRNq88vJy2rdv36YDAcDMaN++/QEdESkURMQX2nog1DrQ/fRNKMxYVcjjHy9Cp/UQEdkz34TC3Lxi/jFhOVtKqyJdioj4TEFBATk5OeTk5NC5c2e6du1ad7+ysnKvz50xYwZ33HFHM1Xqo47mrIwEAPK2lNIuKTbC1YiIn7Rv357Zs2cD8NBDD5GcnMz//u//1j1eXV1NdHTDX8e5ubnk5uY2S53goyOFrIxEAPK2lEW4EhERuPbaa7nlllsYMmQId911F9OmTeP4449n0KBBDB06lMWLFwMwYcIEzjvvPMALlOuvv55hw4bRq1cvnnrqqYNel2+OFLrWO1IQEf/67fvzWfD91oP6mv0PSeXB849o8vPy8vKYPHkygUCArVu3MmnSJKKjo/nss8+47777eOutt3Z7zqJFixg/fjzbtm2jb9++3Hrrrfs9J6EhvgmFtIQYUuOjdaQgIi3GJZdcQiAQAKC4uJhrrrmGpUuXYmZUVTXc//mDH/yAuLg44uLi6NixIxs3biQrK6vBbfeHb0IBvCYkhYKIv+3PL/pwSUpKqlt+4IEHGD58OO+88w6rVq1i2LBhDT4nLi6ubjkQCFBdXX1Qa/JNnwJ4nc1qPhKRlqi4uJiuXbsCMHr06IjV4bNQ8I4UNFdBRFqau+66i3vvvZdBgwYd9F//TdHqrtGcm5vr9vciO6O+WsnD/1nAtw+coWGpIj6ycOFC+vXrF+kymk1D+2tmM51z+xzb6rMjBY1AEhHZG5+FguYqiIjsja9CQXMVRET2zlehoLkKIiJ756tQAM1VEBHZGx+GguYqiIjsia9mNIN3pPDVss0453xz0Q0RiayCggJOO+00ADZs2EAgECAzMxOAadOmERu79yHyEyZMIDY2lqFDh4a9Vh+GQgKllUG2lFZproKINIt9nTp7XyZMmEBycnKzhIIvm49AI5BEJLJmzpzJKaecwjHHHMNZZ53F+vXrAXjqqafo378/AwcOZMSIEaxatYpnnnmGP//5z+Tk5DBp0qSw1uXDI4UdcxUGZqVHuBoRaXYf3QMbvju4r9n5SDjnsUZv7pzj9ttv57333iMzM5PXX3+d+++/n1GjRvHYY4+xcuVK4uLiKCoqIj09nVtuuaXJRxf7y3ehoLkKIhJpFRUVzJs3jzPOOAOAYDBIly5dABg4cCBXXnklF110ERdddFGz1+a7UNBcBRGfa8Iv+nBxznHEEUfwzTff7PbYBx98wMSJE3n//fd55JFH+O67g3xUsw++61MA6Kq5CiISQXFxceTn59eFQlVVFfPnz6empoa1a9cyfPhwHn/8cYqLiykpKSElJYVt27Y1S21hDQUzO9vMFpvZMjO7p4HHu5nZeDObZWZzzezccNZTS3MVRCSSoqKiePPNN7n77rs56qijyMnJYfLkyQSDQa666iqOPPJIBg0axB133EF6ejrnn38+77zzTuvuaDazAPA0cAaQB0w3s3HOuQX1Nvs18IZz7h9m1h/4EOgRrppqZWUkMFlzFUQkAh566KG65YkTJ+72+FdffbXbuj59+jB37txwllUnnEcKxwLLnHMrnHOVwGvAhbts44DU0HIa8H0Y66mTlZHI9sogRaUNXwNVRMSvwhkKXYG19e7nhdbV9xBwlZnl4R0l3N7QC5nZSDObYWYz8vPzD7iwHXMV1K8gIlJfpDuaLwdGO+eygHOBf5nZbjU5555zzuU653Jrp4YfCE1gE/Gf1naVyf11oPsZzlBYB2TXu58VWlffDcAbAM65b4B4oEMYa/IK0cV2RHwlPj6egoKCNh8MzjkKCgqIj4/f79cI5zyF6UBvM+uJFwYjgCt22WYNcBow2sz64YXCgbcP7UNaQgwp8dE6UhDxiaysLPLy8jgYzc8tXXx8PFlZWfv9/LCFgnOu2sxuAz4BAsAo59x8M3sYmOGcGwf8CnjezH6B1+l8rWumKNd1FUT8IyYmhp49e0a6jFYhrDOanXMf4nUg11/3m3rLC4ATwlnDnmRlJLCmQEcKIiL1RbqjOWJqJ7C19TZGEZGm8HEoaK6CiMiufBwKmqsgIrIrhYJGIImI1PFxKGiugojIrnwbCpqrICKyO9+GAmiugojIrnweCgkKBRGRehQKmqsgIlLH56GguQoiIvX5PBQ0V0FEpD5fh0LXdM1VEBGpz9ehkK25CiIiO/F1KKQmRJMSp7kKIiK1fB0KZkbXjATWFelIQUQEfB4KoAlsIiL1KRRCE9g0V0FERKFAVkYCJRXVFJdproKIiEJBI5BEROooFHRdBRGROr4PBc1VEBHZwfehsGOugkJBRMT3oVA7V0HNRyIiCgVAcxVERGopFNBcBRGRWgoFNFdBRKSWQgHNVRARqaVQQHMVRERqKRTQXAURkVoKBTRXQUSklkIBzVUQEamlUAjRXAUREYVCHc1VEBFRKNTRXAUREYVCnR3DUtWEJCL+pVAI2TGBTZ3NIuJfCoUQHSmIiIQ5FMzsbDNbbGbLzOyePWxzqZktMLP5ZjY2nPXsTVpCDMmaqyAiPhcdrhc2swDwNHAGkAdMN7NxzrkF9bbpDdwLnOCc22JmHcNVz76YWd0IJBERvwrnkcKxwDLn3ArnXCXwGnDhLtvcBDztnNsC4JzbFMZ69ilLE9hExOfCGQpdgbX17ueF1tXXB+hjZl+b2RQzOzuM9exTVkYi6zRXQUR8LNIdzdFAb2AYcDnwvJml77qRmY00sxlmNiM/P3//3qlgOUx5Zq+bZGUksK2imq1l1fv3HiIirVw4Q2EdkF3vflZoXX15wDjnXJVzbiWwBC8kduKce845l+ucy83MzNy/ahb9Bz6+GzYu2OMmtSOQ1qoJSUR8KpyhMB3obWY9zSwWGAGM22Wbd/GOEjCzDnjNSSvCUk3OVRCIgxkv7nETXWxHRPwubKHgnKsGbgM+ARYCbzjn5pvZw2Z2QWizT4ACM1sAjAfudM4VhKWgpPYw4GKY8xpUbGtwE11sR0T8LmxDUgGccx8CH+6y7jf1lh3wy9Bf+A2+Eea8CnNf95Z3obkKIuJ3ke5obl5dj4EuR8H0F6GBEUaaqyAifuevUDDzjhA2LYA13zS4ieYqiIif+SsUAAb8GOLSYPoLDT6suQoi4mf+C4XYRBh0JSwYB9s27vaw5iqIiJ/5LxQAcq+HmiqY9fJuD2mugoj4mT9DoUNv6DUMZoyG4M5HBJqrICJ+5s9QABh8E2zNg6Wf7LRacxVExM/8Gwp9zobUrrt1OGuugoj4mX9DIRANx1wHy7+AzcvqVpsZXdM1V0FE/Mm/oQBw9NUQFQ0zRu20WnMVRMSv/B0KKZ2g3wUw+xWo3BECWRkJmqsgIr7k71AAb4ZzeTHMe6tuVVZGouYqiIgvKRS6D4XMfjD9+brzIWmugoj4lULBDAbfAOvnwLpvAc1VEBH/alQomFmSmUWFlvuY2QVmFhPe0prRwMsgNrlueGrtkcK6IoWCiPhLY48UJgLxZtYV+BT4CTA6XEU1u/hULxjmvQWlhaQnxpAUG9AIJBHxncaGgjnnSoGLgb875y4BjghfWREw+AYIVsCsV0LXVUhU85GI+E6jQ8HMjgeuBD4IrQuEp6QI6XQEdBvqXcO5pkYX2xERX2psKPwcuBd4J3Sd5V5411RuWwbfAFtWwfIvNIFNRHypUaHgnPvSOXeBc+7xUIfzZufcHWGurfn1uwCSMmH6C95chfJqisuqIl2ViEizaezoo7FmlmpmScA8YIGZ3Rne0iIgOhaOvgaWfEzv2AJAZ0sVEX9pbPNRf+fcVuAi4COgJ94IpLbnmGvBjP7r3wE0V0FE/KWxoRATmpdwETDOOVcFtM0TA6VnQ59z6LD0dWKpUiiIiK80NhSeBVYBScBEM+sObA1XURE3+AaiSjdzUewMNR+JiK80tqP5KedcV+fcuc6zGhge5toip9dwaNeLq2M+Y87aIoI1bfOgSERkV43taE4zsz+Z2YzQ3x/xjhrapqgoyL2BAcGFlK2dwyMfLIx0RSIizaKxzUejgG3ApaG/rcA/w1VUi5BzBS46nic7fcaor1fw4lcrI12RiEjYRTdyu0Odcz+qd/+3ZjY7HAW1GIntsBN/wYAJjzK6YxLXf3Aph6TFc86RXSJdmYhI2DQ2FMrM7ETn3FcAZnYC0PaH5ZxyN1SVMezrv/BMWiW3vx5FZsrx5PZoF+nKRETCorGhcAvwspmlhe5vAa4JT0ktiBmc/hBERXPmpD/wl/gqRr4Uxb9/ehKHZiZHujoRkYOuUaHgnJsDHGVmqaH7W83s58DccBbXIpjBqb+GqGjO+fIxglbN9aOiefOnJ5OZEhfp6kREDqomXXnNObc1NLMZ4JdhqKdlMoPh98Lw+znPfcmvtv+Fm0ZPobRS13AWkbblQC7HaQetitbilLvg1Ae4IOorbtj0KD8bM4PqYE2kqxIROWgOJBT8OaPr5P+F03/L+YFvuHDFb/jte3Nwzp//FCLS9uw1FMxsm5ltbeBvG3BIM9XY8pz4czjzEc4LTOWEWXfy7PhFka5IROSg2GsoOOdSnHOpDfylOOcaO3KpbRp6GzVnPcrZgen0Gv8/jPtWk9tEpPU7kOYj34s6/qdUnf0EZwZmkvzu9XyzZF2kSxIROSAKhQMUc9zNlJ35JKdGfUv12CtZkpcf6ZJERPZbWEPBzM42s8VmtszM7tnLdj8yM2dmueGsJ1wSho5ky2l/4CRmseXFH7OpYEukSxIR2S9hCwUzCwBPA+cA/YHLzax/A9ulAD8DpoarluaQcdJNrDv5SYa42Ux59ZFIlyMisl/CeaRwLLDMObfCOVcJvAZc2MB2vwMeB8rDWEuz6HrqSPJSBzFg0/vMXFUQ6XJERJosnKHQFVhb735eaF0dMzsayHbOfbC3FzKzkbXXcsjPb9lt9pknXUevqA288e7b1OjiPCLSykSso9nMooA/Ab/a17bOueecc7nOudzMzMzwF3cA4gZeTHUggZzNH/DeHI1GEpHWJZyhsA7Irnc/K7SuVgowAJhgZquA44BxrbWzuU5cCoEBF3FhzBT+8uFcnR9JRFqVcIbCdKC3mfU0s1hgBDCu9kHnXLFzroNzrodzrgcwBbjAOTcjjDU1C8u5kkRXRs72STw3cUWkyxERabSwhYJzrhq4DfgEWAi84Zybb2YPm9kF4XrfFqH7CZDenVvTpvDslytYX9z2r0ckIm1DWPsUnHMfOuf6OOcOdc49Elr3G+fcuAa2HdYWjhIAiIqCnCvoWzaLTm4TT368ONIViYg0imY0h8tRIzAcD/eYx9uz1jFnbVGkKxIR2SeFQrhk9IAeJ3Fiyad0SIrld/9ZoFNsi0iLp1AIp5wriSpayeODS5ixegsffLc+0hWJiOyVQiGc+l8AsckML/8v/bqk8uiHiyivCka6KhGRPVIohFNsEhxxEVHz3+XBs7qxrqiMF7/SdRdEpOVSKIRbzpVQtZ3jyidzZv9O/H38MjZta/WneRKRNkqhEG7djoeMnjB7DPed24/KYA1//GRJpKsSEWmQQiHczLyjhVWT6BHI59qhPXhj5lrmrSuOdGUiIrtRKDSHo0YABnNe47ZTe5ORqCGqItIyKRSaQ3o29DoFZo8hLS7AL87ow9SVhXwyf2OkKxMR2YlCobnkXAVFa2D111w+OJs+nZJ59KOFVFRriKqItBwKheZy+A8gLhVmjyE6EMWvf9Cf1QWlvDx5daQrExGpo1BoLrGJcMQPYcF7ULGNk/tkMrxvJk99vpSCkopIVyciAigUmtegq6Cq1AsG4P4f9Ke0KsifP9MQVRFpGRQKzSlrMLTvDbPGAHBYx2R+clx3xk5dwwdzdV4kEYk8hUJzMoOcK2DNZChYDsCdZ/Xl6G4Z/Oy1WXwyf0OECxQRv1MoNLejRoBFwZzXAEiKi+af1w3myKw0bhv7LZ8v1DBVEYkchUJzSz0Eeg2HOa9CTQ0AKfExjL7uWPp1SeXWV77lyyX5ES5SRPxKoRAJg66E4rWwamLdqrSEGF6+/lgO65jMyJdn8PWyzREsUET8SqEQCX1/APFpdR3OtdITY3nlxiH07JDEDS9N55vlBREqUET8SqEQCTHxMODHsPB9KN/5xHjtkrxgyM5I5IaXpjN9VWGEihQRP1IoRErOlVBdBvPf3e2hDslxjLlpCJ1T47l21DS+XbMlAgWKiB8pFCKl69HQoS/MHtPgwx1T4hl703F0SInjmhenMTevqJkLFBE/UihEipnX4bx2Kmxe1uAmndPiefWm40hPiuGqF6bqGgwiEnYKhUgaeBlYAOaM3eMmh6QnMPbG40iJj+GqF6eycP3WZixQRPxGoRBJKZ3hsNNh9qtQtud+g+x2iYy9aQjx0QGuemEqSzdua8YiRcRPFAqRdvxPYfsmeOZkWDttj5t1b5/E2JuGEBVlXP78VJZtKmnGIkXELxQKkdZrGFz/qdfHMOps+OrPdTOdd9s0M5lXbxoCOK54fgor8hUMInJwKRRagqxj4JZJ0O98+OwhGPNjKGn4VBeHdUxhzI3HEaxxXP78FFZu3t68tYpIm6ZQaCni0+CS0XDen2H11/DMCbDiywY37ds5hTE3DaEq6Lj8uSmsainBUF0JFTp6EWnNFAotiRnkXg83feGFxMsXwhe/h2D1bpse3jmVV24YQkV1kMufn8LqgggHw+Zl8Pch8PxwCFZFthYR2W8KhZao0xEwcoI363nik/DS+VC8brfN+h+Syis3DqGsKsjlz01hbWFps5cKwKqv4cXToWQTbF4C374cmTpE5IApFFqq2CS46Gm4+HnYMNdrTlr80W6bHXFIGq/cMITtlUFGRCIY5r4B/7oIEjt4/SLZx8GXT0BlhAJKRA6IQqGlG3gpjPwS0rLh1RHw8b1e2309A7qmMebGIWwrr+Ly56eQt6XeF7JzULENtn6/x1FN+8U5mPA4vH0TZA+BG/8L7XrB6Q9ByQaY9uzBey8RaTbmnIt0DU2Sm5vrZsyYEekyml91BXz6gPdl2yUHTr4TKrd7k97Ki6BsC1sKNvLdslVkRJVyeFqQmIoi77GaUJ9Elxw447feMNgDrWXcHTD3NTjqcjj/KYiO3fH4mEu8ORc/mwMJ6Qf2XiJyUJjZTOdc7j63Uyi0Mgv/A+/9dLdTbhOXBgnplAZSmFNglAVSGdL/UJLSOkBChrfNtOe8i/scepr3i77LwKa/f2khvP4TWP0VDL/fCyeznbdZPxeePQlO+hWc9pv92UsROcgUCm3Z9gLYstL7so9P90YqBaLrHp69toifvDCVdsmxvD7yeDqnxXsPVJXD9Bdg0h+8I4wjL4VTfw0Z3Rv3voUrvKOAojVw4dNe09aevHkDLP4Q7pgNKZ0OYGdF5GBobCioT6E1SmoPWbnQ/lBvuV4gAORkp/PyDcdSUFLJ5c9PYUNxufdATDwMvc37oj7xF7BwHPwt1+un2L6Pq7ytmQovnA6lBXD1e3sPBIDh90Gw0hs9JSKtRlhDwczONrPFZrbMzO5p4PFfmtkCM5trZp+bWSN/ssq+DOqWwUvXH8umreVc8fwUNm4t3/FgQrrXfHT7t96ZWqc+A0/lwKQ/NjxqaN5b3rDY+DS44TPoPnTfBbQ/FI6+Gmb+EwpXHqzdEpEwC1vzkZkFgCXAGUAeMB243Dm3oN42w4GpzrlSM7sVGOacu2xvr6vmo6aZsaqQa0ZNo1NqPCOOzaa8qoaK6uBOt+klyzgv/wVySidTGNWesYlX8GHgNGKio3ms02f0W/AXb6jpiLHekUljbV0PTw2C/hfAxc+FbydFZJ8i3qdgZscDDznnzgrdvxfAOffoHrYfBPzNOXfC3l5XodB001cVcsPo6Wwt90YhRUcZ8TEB4qKj6m7jYgIMqlnAtaX/pE/VQtbHdGOpy+bk6q/5Mu4UYn/0D47v07Xpb/7fB+Hrv8KtX3uT8kQkIlpCKPwYONs5d2Po/k+AIc652/aw/d+ADc653zfw2EhgJEC3bt2OWb16dVhqbssqqoNUBx1x0VFEB/bSaugcLPrAOzFfwVIW9r6ZG1afyfdbKzj18I7cffbh9O2c0vg3LtsCfznKa3K64rUD3g8R2T+NDYXofW3QHMzsKiAXOKWhx51zzwHPgXek0IyltRlx0QHiGvNpm0G/86DP2VC0mn7tD+WLqiAvTV7F38Yv45y/TuSSY7L5xRl9doxq2puEDDjhDvjid15ndbchB7wvIhI+4exoXgdk17ufFVq3EzM7HbgfuMA5VxHGeqQpAtFeZzEQHxPg5lMOZeKdw7n+hJ68M2sdw/4wnj98spht5Y04+d1xt0JSR/j8t96RiIi0WOEMhelAbzPraWaxwAhgXP0NQv0Iz+IFwqYw1iIHQUZSLL8+rz+f/+oUzjqiM38bv4xTnpzAS5NXUVm9l1NoxCbBKXd5pwRf9nnzFSwiTRa2UHDOVQO3AZ8AC4E3nHPzzexhM7sgtNmTQDLwbzObbWbj9vBy0oJkt0vkryMG8f5tJ9K3UwoPjpvPmX/+kg/mrmePfVRHXwPp3b2jhYN5DiYROag0o1kOiHOOCUvyeezDRSzeuI32SbGkJsSQGBsgKTaaxLjQbWyA40s+4+LVD/NJv0f5PusckuK89ZXVNZRUVHt/5dVsr6hmW+1ypXdb/3EHnHVEZy4bnM2Qnu2wXU+zISK7ifjoo3BRKLRMwRrHO7PWMX1lIaVVQUorvC/00sog2yu827KKSl6vuZMYqjiz8gmqGxjnEB1lJMdHkxQbTUp8NMlx0STFRZMcH01KaLmkvJoP561nW3k1PdoncungbH58dBYdUxvR8d1YFSUQkwBRgYP3miIRpFCQFskt+hB77XK2n/lHtvS7gtLKILGBKJJDARAXHdWoX/5llUE+mree16avZdrKQgJRxvC+HRkxOJthfTP3Pux2X5Z8Cm9e750T6twnGzeDW6SFUyhIy+QcvHimd7bWO2Z5v8YP0Ir8Et6YkcebM/PYXFJBx5Q4LsnN4tLcbLq3T2pabVOfgU/ug8x+ULHVq3PgCDjjYZ3YT1o1hYK0XKu+htHnel+0J/zsoL1sVbCGLxZt4o3paxm/eBM1Do7v1Z7LBmdz9oDOxMfspSkoWAUf3QUzRsHh5+04LcekP8Lk/4PoeO8kf4Nv2u0EhCKtgUJBWrZXfgTrZnoX4olPO+gvv6G4nDdnruWNGXmsKSwlMyWOe84+nB8O6kpU1C7NU2VF8O9rYMUEOOHncNqDEFWv+WnzMvjoTlj+BXQaoCYlaZUUCtKyrZ8Dz57sXaTn1F+H7W1qahyTlxfw5KeLmbO2iKO7pfPwhTM9zDkAABCPSURBVAMY0DUURAXLvcucFq6E8/8Kg65s+IWcg4Xve01LalKSVkihIC3fv6+DJR/DDZ9613eObUL7fxPV1Dje/DaPJz5eRMH2SkYM7sa9/TeT+t513gaXjYEeez0Xo6dyu9ek9PVTXn+ImpSklVAoSMtXsByePnbHNaRjUyC5I6R09m6TO+38lxK6TWy/30NFi8uq+OtnSymZOppHol+gNCmbpGvfIjrzsKa9kJqUpJVRKEjrsGkhfD8LSjbCto3ebckmKNng3VZs3f05gTjvC/iw0+Gw0yDz8N2vE70nNTXerOqv/8J3cYO4svhWDunchYcuOILjejXhWhGwo0np43thax4M+BH0GgbtDvXOG5XcqfF1iYSZQkHahsrtoZCoFxgFy2HFeMhf5G2T2tULh8NOh56neFeW29NrvT0SFv0Hcq/Hnf04Hy8s4PcfLGRdURnnH3UI9517OF3SmjhMtrZJ6ZunobreFe5ik6FdT69prDYoam+TMhUY0qwUCtL2Fa2F5Z97J9lbMcE7qrAAZB8Lh57mBUWXHG8kUfE6r0N54zw461EYcnPdl3JZZZB/fLmcZ75cTsCM2049jBtP6klcdOOaqJxzVFTXUFlVScL274kpWgmFK6BwuRdghcthy2pwwR1Pik3xAiPzcOh6jPfXZSBEx4XhH8qnKkth3O3ej4Qzf39Q5sS0ZgoF8ZdgFeTNgGWfeUHx/SxvfWJ7OPRUWDnJ+0X/41HQ58wGX2JtYSm/+88CPl2wke7tExncox3lVUHKq4KUVXmXLi2rDFJeHaS8cse68urgTmcEj42OqjslR1JcNMlxAdJiISuqgG6s55Dg93SqXkeHijwyS5cSX57vPTEqBjofCVm50DXXu23Xq/FHFMEqL3wKlkLBMtgcui3Z6M29GHIzpB5yAP/IrUh5MYy9DNZMARx0OQouewXSu0W6sohRKIi/leR7TUzLPvM6g+NS4bJ/NeqSoBOX5PPkJ4spKKkgPjZAfHSAhNgA8TFRJMQEiA/9JcSE1kdHER8bIDYQVXeup5KK6rpbbzlYb9k7F1StzhRwRupaTk1ZywC3lPZb5xNVXeY9mJCx40iia65364KhL/zaL/9l3vKWVTs67cELxPa9vVFdK8Z7R1EDfgRDb/PCp63aXgCv/BA2zoeLn/eOEN4eCVHR8OMXvR8JPqRQEKlV+994C2rDD9Y4tldWs3pzKVNXFjBtZSHTVhVSVFpFgCDHp+RzXvvvyY1eQXbpAmILF2M08P9qIM7ro2h/GHTo7d227+2tS2y3Y7vCld4pPL79F1Rt9/peht7u9cO0oH+XA7b1e3j5IihaDZf+a8dRYcFyeO1K2LwYTn0ATvxF29rvRlAoiLQyNTWOpZtKmLqygKkrCpm6spDNJd7FCLsl1XBx53xOSlpDekoyUZl9iOvcl5SO3UlOiGv86cPLtsDM0TD1Wdi23uvTOP5/4MhLIWbHWWZrahzFZVVsKa30/rZXUVhaSVFpJVtKq9iyfcf6LaWVFJVVcXjnFG48qRcn9+4QmdOZF66Ely+E0gK44nXoceLOj1eUeH0M89+GfufDhX+H+NTmrzNCFAoirZxzjhWbtzNtZSFTVxQwdWUh64vLd9suEGWkJ8SQlhhDekIM6Ymx9e7HkhwfTWV1DWWhU5mXVgWprCinf8FnnFb0Bt2rVrDF0nk7+hxec2eyviqJ7ZXVe7xyakzAyEiMJSMxlvTEGNolxZISH82Exfls2lZRFw4XHHUIsTXlsHUdFK2B4rzQ31rvtrQQjroMjr15p0DaL5sWeYEQrICr3vKa2Rr+R/VGif33N97R1GVjILPPgb13U9UE4cvHoboCTvy510TYDBQKIm2Mc451RWWsLy6nqNT7hV5cWkVRWSVFpVUUlVXtdL+4tIptFdU7vUZCTICkOK8vJDEmmoSYKAYzj/O3v83AsqlUWSxz2p/L8s7nkJQQT2pcFClx5t3GRpESa8QHHOZqvC83F/Rua4JUl+SzctkiNq5dRmrlBrKiCmjHLvNMLApSukBa6PLta6d4y6c+AEdesvM5pxrr+1nwr4shEAM/eRc69d/3c1ZOgjevg6oyuOgf0P+CfT/nYKgogbduhCUfeffj071L1Q6+MewjzxQKIkJVsIaS8mriYqKIjw7sfjLA+jYtgilPw5zXvV/c+yMmEZeWzZaYTszemszMomQ2BzrSv19/zhyaS5esXt6Xd60VX8J/H/DOhdV5IJz5O28CYGOtngxjLoXEDLj6PW+0VmMVr4M3roZ1M7w+hlMfCO9Flbauh1cvgw3fwTlPQLfj4NMHvEEAGT3g9Ieg/0Vh6+tQKIjI/inJ9359W5T3y90C3sidqEBouXZdaH3tckKG91fvS23+98W8MGkl78/5Hgf84Mgu3HRSL47Mqndm3JoamPcWfP4wFK/xOr/PeHjfI8WWfgavXwXp2fCTdylN6MSawlLWFJSyprCU1aHbdkmxnNS7Ayf27kDHlF2aqaor4KO7YeY/vTD60ShIauLM9sbYMA/GXuoNlf3xP3ceFr3sMy8cNi2ArGO9ORXdhhz0EhQKItJifF9UxujJqxg7dQ0lFdUc36s9153Qg+x2iQSijCgzomsqSP1uNOkz/opVbqO8/2WUnnAPlnYIUQZRUUZ5VZC1haVUffcOg2fexfrYnjyQ+jDzimLJ37bz0U1KfDTd2iWyvricwu2VAPTrksrJvTtwcp9MjumeseMaG9/+Cz74lXfOrcv+BYcMOng7v/Qz79TscaleB3iXgbtvUxOE2WPgi0e8U7z0v9A7cmjKkc8+KBREpMXZWl7F69PWMurrlQ12mgOkUcL/RL/HNYFPqCGKF4Pn8Ez1+ZSQCMAlgQk8Fv0837re3B//AO06ZNKtXSLd2yfRrV1iaDmR9MRYwBtJtWD9ViYuzWfiknxmrt5CVdARHxPFcb3ac1LvTE7p04FDq5Zib1ztnUrluFu9UVnJHQ9sh6e/AB/e5fVzXPHGvicPVpTAN3+Dr//qTUY89ibv9PL1hxfvJ4WCiLRYVcEavllewPaKamocBJ2jpsYRrHF1ywnb1zFwyVP0XP8hZTEZzOo5khgLMnjxHyjNPpmoEWOIT2r6kNLtFdVMWVHApKWbmbg0nxX52wE4JC2es3rGcOP2Zzkk70MsEAuDroKhd3jX626KmqA3wumbv0Hvs7yZ9HHJdQ9v2V6JA9olxTb8/G0bYPwjMOsViEvxguHYkQfUGa1QEJG24ftZXpv7qkne/cPP875kD9JonbWFpXy1bDMTl+Tz9bLNbC2vplfURu5P/5RhZf8lCgcDL8FO/CVk9t33C9Y/8eKxN8PZj1JDFN+tK2b84k2MX5zP3LwinINeHZI4unsGx3TPILd7BodmJu88GGDjAi9clv3XO0XHeX/2+lz2g0JBRNoO57wO2Y3z4Pjbw3ZRo+pgDXPyivhi0SY+X7iJog2ruCn6Q66I/oJ4KinIPpO0M+4mptse5kFs2+iNMFo/h7JTf8/naT9k/KJ8vlyyic0llZhBTnY6w/p0JC4mipmrtzBz9Za6Po/U+GgvJLplcEyPDHKy00mMjfZO1fLpb+Cs3zdtdFY9CgURkQO0rqiMLxZtYvq8xfRdM5af2CekWikLEnPZdNRtDBh6Dh1CI5rcxvlU/+sSKC3gT6n38NymvgRrHGkJMZzSJ5Phh2dycu9M2ifvfITjnGNVQWkoIAqZuXoLSzaWAN7ExH5dUsjt3o6ju6Vx3KENjKBqJIWCiMhBVFpZzdSFqyn/5jmGbHiVdhQzs6Y3H2dcQYe0ZK5c8yDbXSzXV94JXY5ieN+ODD88k5zsDAJ7mx/SgOLSKr5du4VvQ0cSs9cWUVoZ5OELj+Dq43vsV/0KBRGRMHGVpayf8ALJM/9OasV6APJiezHrxGc5NmcgnVIP8LQdu6gO1rBowzY6pcaTmbJ/fSkKBRGRcAtWwXf/9ianDb/XGynUQjU2FMLTWyMi4geBGMi5ItJVHFT7cfYpERFpqxQKIiJSR6EgIiJ1FAoiIlJHoSAiInUUCiIiUkehICIidRQKIiJSp9XNaDazfGD1fj69A7D5IJbT2vh5//287+Dv/de+e7o75zL39YRWFwoHwsxmNGaad1vl5/33876Dv/df+960fVfzkYiI1FEoiIhIHb+FwnORLiDC/Lz/ft538Pf+a9+bwFd9CiIisnd+O1IQEZG9UCiIiEgd34SCmZ1tZovNbJmZ3RPpepqTma0ys+/MbLaZtfnL1pnZKDPbZGbz6q1rZ2b/NbOloduMSNYYLnvY94fMbF3o859tZudGssZwMbNsMxtvZgvMbL6Z/Sy03i+f/Z72v0mfvy/6FMwsACwBzgDygOnA5c65BREtrJmY2Sog1znniwk8ZnYyUAK87JwbEFr3BFDonHss9KMgwzl3dyTrDIc97PtDQIlz7g+RrC3czKwL0MU5962ZpQAzgYuAa/HHZ7+n/b+UJnz+fjlSOBZY5pxb4ZyrBF4DLoxwTRImzrmJQOEuqy8EXgotv4T3P0ubs4d99wXn3Hrn3Leh5W3AQqAr/vns97T/TeKXUOgKrK13P4/9+MdqxRzwqZnNNLORkS4mQjo559aHljcAnSJZTATcZmZzQ81LbbL5pD4z6wEMAqbiw89+l/2HJnz+fgkFvzvROXc0cA7wP6EmBt9yXptp22833eEfwKFADrAe+GNkywkvM0sG3gJ+7pzbWv8xP3z2Dex/kz5/v4TCOiC73v2s0DpfcM6tC91uAt7Ba07zm42hNtfattdNEa6n2TjnNjrngs65GuB52vDnb2YxeF+IY5xzb4dW++azb2j/m/r5+yUUpgO9zaynmcUCI4BxEa6pWZhZUqjTCTNLAs4E5u39WW3SOOCa0PI1wHsRrKVZ1X4hhvyQNvr5m5kBLwILnXN/qveQLz77Pe1/Uz9/X4w+AggNw/oLEABGOeceiXBJzcLMeuEdHQBEA2Pb+r6b2avAMLzTBm8EHgTeBd4AuuGdev1S51yb65Ddw74Pw2s6cMAq4OZ6bexthpmdCEwCvgNqQqvvw2tX98Nnv6f9v5wmfP6+CQUREdk3vzQfiYhIIygURESkjkJBRETqKBRERKSOQkFEROooFER2YWbBemeUnH0wz6prZj3qn8FUpKWJjnQBIi1QmXMuJ9JFiESCjhREGil0XYonQtemmGZmh4XW9zCzL0InHPvczLqF1ncys3fMbE7ob2jopQJm9nzonPefmllCxHZKZBcKBZHdJezSfHRZvceKnXNHAn/DmyEP8H/AS865gcAY4KnQ+qeAL51zRwFHA/ND63sDTzvnjgCKgB+FeX9EGk0zmkV2YWYlzrnkBtavAk51zq0InXhsg3OuvZltxru4SVVo/XrnXAczyweynHMV9V6jB/Bf51zv0P27gRjn3O/Dv2ci+6YjBZGmcXtYboqKestB1LcnLYhCQaRpLqt3+01oeTLemXcBrsQ7KRnA58Ct4F0S1szSmqtIkf2lXygiu0sws9n17n/snKsdlpphZnPxfu1fHlp3O/BPM7sTyAeuC63/GfCcmd2Ad0RwK95FTkRaLPUpiDRSqE8h1zm3OdK1iISLmo9ERKSOjhRERKSOjhRERKSOQkFEROooFEREpI5CQURE6igURESkzv8HbWv4T6fxohkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}